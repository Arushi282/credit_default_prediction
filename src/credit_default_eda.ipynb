{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766642a0-60e3-457f-a72a-d369de377a2c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for the Taiwan Default Credit data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c40aa-687b-4967-83de-dd16559f6ab7",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79ad1ee-bd31-48e6-9911-3ac283324494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25969f0-05bb-4d46-9257-54bf1bc8ed95",
   "metadata": {},
   "source": [
    "## Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49064da-4f55-4c50-82c6-902328836570",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_credit_df = pd.read_csv('../data/raw/default_credit_card_clients.csv')\n",
    "\n",
    "default_credit_df = default_credit_df.set_index('ID').rename(\n",
    "    columns = {'default payment next month': 'default_payment_next_month'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c838f-75bd-4d48-ab17-6e3ae8c16364",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06916fea-8a59-48a6-9284-9e520ea9c37f",
   "metadata": {},
   "source": [
    "## Summary of the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8bb3c-89ca-4b49-9391-18a2762075ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c77a4a47-0e27-4d77-a29c-e5e70a72a22f",
   "metadata": {},
   "source": [
    "## Partition the data set into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d753fbc-b7b4-4eef-a102-716468dd554c",
   "metadata": {},
   "source": [
    "Before proceeding further, we will split our data set into train and test set. $20$ % of the observations will be included in the test data and $80$ % in the train data set. Overall `default_of_credit_card_clients` has $30,000$ observations, thus the test set should have enough examples to provide good affirmation for the model: more precisely, the train set will have $24000$ observations, and test set $6000$.\n",
    "\n",
    "Also, throughout the data analysis `random_state=123` will be used to make sure the results are consistent.\n",
    "\n",
    "Worthy to note that no EDA will be performed on test data set, as test set is going to serve for the generalization of the model (unseen data for our model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0bc7df-7fbc-4227-96b2-da39ec7f9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train and test sets\n",
    "train_df, test_df = train_test_split(default_credit_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c2faa3-1608-4b56-9e8d-d7adab4cbc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations for train set:  24000\n",
      "The number of observations for test set:  6000\n"
     ]
    }
   ],
   "source": [
    "# printing the number of observations for train and test sets\n",
    "print('The number of observations for train set: ', train_df['default_payment_next_month'].shape[0])\n",
    "print('The number of observations for test set: ', test_df['default_payment_next_month'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8b707b-aa17-495e-8f07-8ecc15d84433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of zeros and ones in default column train set\n",
    "train_percent_defaults = train_df['default_payment_next_month'].value_counts(normalize=True) * 100\n",
    "train_percent_defaults.name = 'Default Count Percent'\n",
    "\n",
    "# count of observations were default is one or zero in train set \n",
    "train_yes_default = len(train_df[train_df['default_payment_next_month'] == 1])\n",
    "train_no_default = len(train_df[train_df['default_payment_next_month'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb43771-bf27-43e0-b6fc-4671de6385f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default Count Percent</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No (0)</th>\n",
       "      <td>77.783333</td>\n",
       "      <td>18668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes (1)</th>\n",
       "      <td>22.216667</td>\n",
       "      <td>5332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Default Count Percent  Count\n",
       "No (0)               77.783333  18668\n",
       "Yes (1)              22.216667   5332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to a dataframe and make column names readable\n",
    "default_percent_df = pd.DataFrame(train_percent_defaults)\n",
    "default_percent_df = default_percent_df.rename(index = {0: 'No (0)', 1: 'Yes (1)'})\n",
    "\n",
    "# make a dictionary of classes count values \n",
    "count_dic_no = {\"Count\": train_no_default \n",
    "               }\n",
    "\n",
    "count_dic_yes = {\"Count\": train_yes_default\n",
    "                }\n",
    "\n",
    "# make a list from classes default payment counts \n",
    "list_default = [count_dic_no, count_dic_yes]\n",
    "\n",
    "# convert to a dataframe\n",
    "default_count = pd.DataFrame(list_default, index = ['No (0)', 'Yes (1)'])\n",
    "\n",
    "# join two dataframes\n",
    "df_default = default_percent_df.join(default_count)\n",
    "df_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d164561-c516-4807-92b7-9323bbd75b29",
   "metadata": {},
   "source": [
    "The count, as well as percentage of overall distribution of classes indicates that there is an imbalance between `No (0)` and `Yes (1)` classes. It is certainly something we have to take into account for later on analysis, however the difference does not seem to be significant enough to start our analysis with over or under sampling assumption. Thus, we will start our analysis without any assumption, and if the confusion matrix or any other indicators during tuning will show that the model makes a lot more mistakes on class `1` (minority class), we will accordingly adjust the model to get the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09b9fa-4fda-4af2-95ed-e33e848d2f41",
   "metadata": {},
   "source": [
    "## Exploratory analysis on the training data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
